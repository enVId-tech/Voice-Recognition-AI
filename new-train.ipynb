{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "NVIDIA GeForce RTX 3070 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \", device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "audio_dir = \"./AUDIO\"\n",
    "csv_file = \"./TEXT/AUDIO.csv\"\n",
    "\n",
    "audio_files = os.listdir(audio_dir)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in audio_files:\n",
    "    if not file.endswith(\".mp3\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(audio_dir, file)\n",
    "\n",
    "    y, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc = np.transpose(mfcc, (1, 0))\n",
    "\n",
    "    x_train.append(torch.tensor(mfcc))\n",
    "\n",
    "    # Find the matching text in the CSV file\n",
    "    matched_text = df.loc[df['Video Matching'] == file, 'Text'].values[0]\n",
    "\n",
    "    y_train.append(matched_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character set\n",
    "characters = list(set(char for label in y_train for char in label)) \n",
    "characters.append('<PAD>')\n",
    "\n",
    "# Create label encoding dicts\n",
    "char_to_id = {char: id for id, char in enumerate(characters)}\n",
    "id_to_char = {id: char for char, id in char_to_id.items()}\n",
    "\n",
    "# Encode labels as integers\n",
    "y_train_ids = [[char_to_id[char] for char in label] for label in y_train] \n",
    "\n",
    "# Pad sequences\n",
    "max_len = max(max(len(mfcc) for mfcc in x_train), max(len(label) for label in y_train_ids))\n",
    "y_train_padded_ids = pad_sequences(y_train_ids, maxlen=max_len, padding='post', value=char_to_id['<PAD>'])\n",
    "\n",
    "# Reshape to 2D array with 1 column \n",
    "y_train_padded_ids = y_train_padded_ids.reshape(-1, 1) \n",
    "\n",
    "# One hot encode\n",
    "onehot_encoder = OneHotEncoder()\n",
    "# Fit on 2D array of IDs\n",
    "onehot_encoder.fit(np.array(list(id_to_char.keys())).reshape(-1, 1))  \n",
    "# Transform padded IDs to one-hot encoding\n",
    "y_train_onehot = onehot_encoder.transform(y_train_padded_ids).toarray()\n",
    "\n",
    "y_train_onehot_padded = pad_sequences(y_train_onehot, maxlen=max_len, padding='post')\n",
    "# Pad input features\n",
    "x_train_padded = pad_sequences(x_train, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        # Use only the last output of each sequence for classification\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(13, 128, len(characters)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your data to PyTorch tensors and move them to the device\n",
    "x_train_tensor = torch.tensor(x_train_padded).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_onehot_padded).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New batch size:  10000\n",
      "Shape of y_train_onehot_padded_subset: (10000, 1, 55)\n"
     ]
    }
   ],
   "source": [
    "# Define the OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder on the label data\n",
    "encoder.fit(y_train_padded_ids)\n",
    "\n",
    "# Correctly one-hot encode y_train_padded_ids\n",
    "y_train_onehot = [encoder.transform(label.reshape(-1, 1)).toarray() for label in y_train_padded_ids]\n",
    "y_train_onehot_padded = np.stack(y_train_onehot)\n",
    "\n",
    "# Define a new, smaller batch size\n",
    "new_batch_size = 10000\n",
    "\n",
    "# Take a subset of your training data\n",
    "y_train_onehot_padded_subset = y_train_onehot_padded[:new_batch_size]\n",
    "\n",
    "print(\"New batch size: \", new_batch_size)\n",
    "# Check the shape of y_train_onehot_padded_subset before it's tiled\n",
    "print(f\"Shape of y_train_onehot_padded_subset: {y_train_onehot_padded_subset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.09845 | Accuracy: 98.00%\n",
      "Epoch 1 | Loss: 0.09845 | Accuracy: 98.00%\n",
      "Epoch 2 | Loss: 0.09845 | Accuracy: 98.00%\n",
      "Epoch 3 | Loss: 0.09844 | Accuracy: 98.00%\n",
      "Epoch 4 | Loss: 0.09844 | Accuracy: 98.00%\n",
      "Epoch 5 | Loss: 0.09844 | Accuracy: 98.00%\n",
      "Epoch 6 | Loss: 0.09844 | Accuracy: 98.00%\n",
      "Epoch 7 | Loss: 0.09844 | Accuracy: 98.00%\n",
      "Epoch 8 | Loss: 0.09843 | Accuracy: 98.00%\n",
      "Epoch 9 | Loss: 0.09843 | Accuracy: 98.00%\n",
      "Epoch 10 | Loss: 0.09843 | Accuracy: 98.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\theli\\Documents\\Visual-Studio-Projects\\Python\\AIProj\\new-python.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theli/Documents/Visual-Studio-Projects/Python/AIProj/new-python.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theli/Documents/Visual-Studio-Projects/Python/AIProj/new-python.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/theli/Documents/Visual-Studio-Projects/Python/AIProj/new-python.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39;49mitem()\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy_score(y_train_tensor\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(),\u001b[39m \u001b[39moutputs\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    outputs = model(x_train_tensor.float())  # Compute outputs in each iteration\n",
    "    outputs = outputs.float()  # Convert to float\n",
    "\n",
    "\n",
    "    y_train_tensor = y_train_tensor.view(-1).long()  # Convert to long\n",
    "\n",
    "    # If the shapes do not match, reshape either outputs or y_train_tensor\n",
    "    if outputs.shape[0] != y_train_tensor.shape[0]:\n",
    "        # Reshape y_train_tensor to match the shape of outputs\n",
    "        y_train_tensor = y_train_tensor[:outputs.shape[0]]\n",
    "\n",
    "    # Now you can calculate your loss\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch} | Loss: {loss.item():.5f} | Accuracy: {accuracy_score(y_train_tensor.cpu().numpy(), outputs.argmax(1).cpu().numpy()) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
